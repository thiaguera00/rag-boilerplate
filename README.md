# ğŸ§  RAG Chatbot Boilerplate â€” FastAPI + LangChain + WebSocket + OPENAI

Este Ã© um boilerplate completo para construir aplicaÃ§Ãµes conversacionais com **LLMs (Large Language Models)** usando a arquitetura **RAG (Retrieval-Augmented Generation)** integrada a um **MCP Server** via **Function Calling**, com comunicaÃ§Ã£o em tempo real via **WebSocket**.

> Ideal para aplicaÃ§Ãµes como assistentes virtuais, chatbots empresariais, atendimento mÃ©dico automatizado e muito mais.

---

## ğŸ“Œ Tecnologias Utilizadas

- ğŸ **Python 3.10+**
- âš¡ï¸ **FastAPI** â€” API REST + WebSocket
- ğŸ”— **LangChain** â€” pipeline RAG, tools e agentes
- ğŸ§  **OpenAI API** â€” LLM + embeddings
- ğŸ—ƒ **FAISS** â€” banco vetorial local
- ğŸ”§ **Function Calling** â€” integraÃ§Ã£o dinÃ¢mica com serviÃ§os

---

## ğŸ§± Estrutura do Projeto
```bash
â”œâ”€â”€ app/ # WebSocket + FastAPI app
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â”œâ”€â”€ websocket.py
â”‚ â”‚ â””â”€â”€ health.py
â”œâ”€â”€ services/ # LÃ³gica do bot, agents, tools
â”‚ â”œâ”€â”€ bot_service.py
â”‚ â”œâ”€â”€ bot_tools.py
â”œâ”€â”€ infrastructure/ # IntegraÃ§Ãµes externas (LLM, vetorstore)
â”‚ â”œâ”€â”€ rag_pipeline.py
â”‚ â”œâ”€â”€ llm_client.py
â”œâ”€â”€ utils/ # ConfiguraÃ§Ãµes, utilitÃ¡rios
â”‚ â”œâ”€â”€ config.py
â”‚ â”œâ”€â”€ utils.py
â”œâ”€â”€ base.txt # Base de conhecimento usada no RAG
â”œâ”€â”€ .env.example # Exemplo das variÃ¡veis de ambiente
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš™ ConfiguraÃ§Ãµes do projeto

Ã‰ necessÃ¡rio uma API KEY da OPENAI para utilizar a LLM, atualmente o RAG Ã© feito utilizando uma base de conhecimento do tipo txt na raiz do projeto onde Ã© necessÃ¡rio criar essa base de conhecimento e colocar na raiz do projeto.

## ğŸš€ Planos futuros

A ideia Ã© ter suporte para adicionar a base de conhecimento para vÃ¡rios tipos como PDF docx e etc. </br>

